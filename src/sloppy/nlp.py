# -*- coding: utf-8 -*-
'''
Created on 24-08-2013

@author: Krzysztof Langner
'''

def tokenize(sentence):
    return sentence.split(' ')